---
title: Foundations of Inference
author: ''
date: '2021-10-13'
slug: foundations-of-inference
categories: []
tags:
  - Inference
---

<script src="{{< blogdown/postref >}}index.en_files/header-attrs/header-attrs.js"></script>


<p>One of the foundational aspects of statistical analysis is inference, or the process of drawing conclusions about a larger population from a sample of data. Although counter intuitive, the standard practice is to attempt to disprove a research claim that is not of interest. For example, to show that one medical treatment is better than another, we can assume that the two treatments lead to equal survival rates only to then be disproved by the data. Additionally, we introduce the idea of a p-value, or the degree of disagreement between the data and the hypothesis. We also dive into confidence intervals, which measure the magnitude of the effect of interest (e.g. how much better one treatment is than another).</p>
<div id="introduction-to-ideas-of-inference" class="section level2">
<h2>1- Introduction to ideas of inference</h2>
<p>In this chapter, you will investigate how repeated samples taken from a population can vary. It is the variability in samples that allow you to make claims about the population of interest. It is important to remember that the research claims of interest focus on the population while the information available comes only from the sample data.</p>
</div>
<div id="working-with-the-nhanes-data" class="section level2">
<h2>1-5 Working with the NHANES data</h2>
<p>Throughout this chapter, you will use the NHANES dataset from the NHANES R package. The data are collected by the Center for Disease Control (CDC, the national public health institute in the United States) and can be thought of as a random sample of US residents.</p>
<p>Before moving on to investigate particular variables, you’ll have an opportunity to briefly explore the data in this exercise.</p>
<pre class="r"><code>library(NHANES)

# What are the variables in the NHANES dataset?
colnames(NHANES)</code></pre>
<pre><code>##  [1] &quot;ID&quot;               &quot;SurveyYr&quot;         &quot;Gender&quot;           &quot;Age&quot;             
##  [5] &quot;AgeDecade&quot;        &quot;AgeMonths&quot;        &quot;Race1&quot;            &quot;Race3&quot;           
##  [9] &quot;Education&quot;        &quot;MaritalStatus&quot;    &quot;HHIncome&quot;         &quot;HHIncomeMid&quot;     
## [13] &quot;Poverty&quot;          &quot;HomeRooms&quot;        &quot;HomeOwn&quot;          &quot;Work&quot;            
## [17] &quot;Weight&quot;           &quot;Length&quot;           &quot;HeadCirc&quot;         &quot;Height&quot;          
## [21] &quot;BMI&quot;              &quot;BMICatUnder20yrs&quot; &quot;BMI_WHO&quot;          &quot;Pulse&quot;           
## [25] &quot;BPSysAve&quot;         &quot;BPDiaAve&quot;         &quot;BPSys1&quot;           &quot;BPDia1&quot;          
## [29] &quot;BPSys2&quot;           &quot;BPDia2&quot;           &quot;BPSys3&quot;           &quot;BPDia3&quot;          
## [33] &quot;Testosterone&quot;     &quot;DirectChol&quot;       &quot;TotChol&quot;          &quot;UrineVol1&quot;       
## [37] &quot;UrineFlow1&quot;       &quot;UrineVol2&quot;        &quot;UrineFlow2&quot;       &quot;Diabetes&quot;        
## [41] &quot;DiabetesAge&quot;      &quot;HealthGen&quot;        &quot;DaysPhysHlthBad&quot;  &quot;DaysMentHlthBad&quot; 
## [45] &quot;LittleInterest&quot;   &quot;Depressed&quot;        &quot;nPregnancies&quot;     &quot;nBabies&quot;         
## [49] &quot;Age1stBaby&quot;       &quot;SleepHrsNight&quot;    &quot;SleepTrouble&quot;     &quot;PhysActive&quot;      
## [53] &quot;PhysActiveDays&quot;   &quot;TVHrsDay&quot;         &quot;CompHrsDay&quot;       &quot;TVHrsDayChild&quot;   
## [57] &quot;CompHrsDayChild&quot;  &quot;Alcohol12PlusYr&quot;  &quot;AlcoholDay&quot;       &quot;AlcoholYear&quot;     
## [61] &quot;SmokeNow&quot;         &quot;Smoke100&quot;         &quot;Smoke100n&quot;        &quot;SmokeAge&quot;        
## [65] &quot;Marijuana&quot;        &quot;AgeFirstMarij&quot;    &quot;RegularMarij&quot;     &quot;AgeRegMarij&quot;     
## [69] &quot;HardDrugs&quot;        &quot;SexEver&quot;          &quot;SexAge&quot;           &quot;SexNumPartnLife&quot; 
## [73] &quot;SexNumPartYear&quot;   &quot;SameSex&quot;          &quot;SexOrientation&quot;   &quot;PregnantNow&quot;</code></pre>
<pre class="r"><code>nrow(NHANES)</code></pre>
<pre><code>## [1] 10000</code></pre>
<pre class="r"><code>levels(NHANES$HealthGen)</code></pre>
<pre><code>## [1] &quot;Excellent&quot; &quot;Vgood&quot;     &quot;Good&quot;      &quot;Fair&quot;      &quot;Poor&quot;</code></pre>
<pre class="r"><code># Create bar plot for Home Ownership by Gender
ggplot(NHANES, aes(x = Gender, fill = HomeOwn)) + 
  # Set the position to fill
  geom_bar(position = &quot;fill&quot;) +
  ylab(&quot;Relative frequencies&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-2-1.png" width="672" /></p>
<pre class="r"><code># Density plot of SleepHrsNight colored by SleepTrouble
ggplot(NHANES, aes(x = SleepHrsNight, color = SleepTrouble)) + 
  # Adjust by 2
  geom_density(adjust = 2) + 
  # Facet by HealthGen
  facet_wrap(~ HealthGen)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-2-2.png" width="672" /></p>
</div>
<div id="calculating-statistic-of-interest" class="section level2">
<h2>1-6 Calculating statistic of interest</h2>
<p>Using the NHANES dataset, let’s investigate the relationship between gender and home ownership. Remember, more information about the dataset can be found here:</p>
<p><a href="https://www.rdocumentation.org/packages/NHANES/versions/2.1.0/topics/NHANES" class="uri">https://www.rdocumentation.org/packages/NHANES/versions/2.1.0/topics/NHANES</a></p>
<p>As seen in the video, natural variability can be modeled from shuffling observations around to remove any relationships that might exist in the population. However, before you permute the data, you need to calculate the original observed statistic. In this exercise, you will calculate the difference in proportion of home owners who are men versus women.</p>
<p>Recall that:</p>
<p>%in% returns a logical vector that is TRUE when values on the left hand side are listed on the right hand side.
The mean of a logical vector is the proportion of cases where that vector is TRUE.</p>
<p>fruits &lt;- c(“apple”, “banana”, “cherry”)</p>
<p>fruits %in% c(“banana”, “cherry”)</p>
<p>mean(fruits %in% c(“banana”, “cherry”))</p>
<pre class="r"><code># From previous step
homes &lt;- NHANES %&gt;%
# Select Gender and HomeOwn
  select(Gender, HomeOwn) %&gt;%
# Filter for HomeOwn equal to &quot;Own&quot; or &quot;Rent&quot;
  filter(HomeOwn %in% c(&quot;Own&quot;, &quot;Rent&quot;))

diff_orig &lt;- homes %&gt;%   
  # Group by gender
  group_by(Gender ) %&gt;%
  # Summarize proportion of homeowners
  summarize(prop_own = mean(HomeOwn==&quot;Own&quot;)) %&gt;%
  # Summarize difference in proportion of homeowners
  summarize(obs_diff_prop = diff(prop_own)) # male - female
  
# See the result
diff_orig</code></pre>
<pre><code>## # A tibble: 1 x 1
##   obs_diff_prop
##           &lt;dbl&gt;
## 1      -0.00783</code></pre>
</div>
<div id="randomized-data-under-null-model-of-independence" class="section level2">
<h2>1-7 Randomized data under null model of independence</h2>
<p>The infer package will allow you to model a particular null hypothesis and then randomize the data to calculate permuted statistics. In this exercise, after specifying your null hypothesis you will permute the home ownership variable 10 times. By doing so, you will ensure that there is no relationship between home ownership and gender, so any difference in home ownership proportion for female versus male will be due only to natural variability.</p>
<p>This exercise will demonstrate the first three steps from the infer package:</p>
<p><em>specify</em> will specify the response and explanatory variables.</p>
<p><em>hypothesize</em> will declare the null hypothesis.</p>
<p><em>generate</em> will generate resamples, permutations, or simulations.</p>
<p>The homes dataset you created in the last exercise is available in your workspace.</p>
<pre class="r"><code># Specify variables
homeown_perm &lt;- homes %&gt;%
  specify(HomeOwn ~ Gender, success = &quot;Own&quot;)

# Print results to console
homeown_perm</code></pre>
<pre><code>## Response: HomeOwn (factor)
## Explanatory: Gender (factor)
## # A tibble: 9,712 x 2
##    HomeOwn Gender
##    &lt;fct&gt;   &lt;fct&gt; 
##  1 Own     male  
##  2 Own     male  
##  3 Own     male  
##  4 Own     male  
##  5 Rent    female
##  6 Rent    male  
##  7 Own     male  
##  8 Own     female
##  9 Own     female
## 10 Own     female
## # ... with 9,702 more rows</code></pre>
<pre class="r"><code># Hypothesize independence
homeown_perm &lt;- homes %&gt;%
  specify(HomeOwn ~ Gender, success = &quot;Own&quot;) %&gt;%
  hypothesize(null = &quot;independence&quot;)  </code></pre>
<pre class="r"><code># Perform 10 permutations
homeown_perm &lt;- homes %&gt;%
  specify(HomeOwn ~ Gender, success = &quot;Own&quot;) %&gt;%
  hypothesize(null = &quot;independence&quot;) %&gt;% 
  generate(reps = 10, type = &quot;permute&quot;) 


# Print results to console
homeown_perm</code></pre>
<pre><code>## Response: HomeOwn (factor)
## Explanatory: Gender (factor)
## Null Hypothesis: independence
## # A tibble: 97,120 x 3
## # Groups:   replicate [10]
##    HomeOwn Gender replicate
##    &lt;fct&gt;   &lt;fct&gt;      &lt;int&gt;
##  1 Own     male           1
##  2 Own     male           1
##  3 Own     male           1
##  4 Own     male           1
##  5 Own     female         1
##  6 Own     male           1
##  7 Own     male           1
##  8 Rent    female         1
##  9 Rent    female         1
## 10 Own     female         1
## # ... with 97,110 more rows</code></pre>
</div>
<div id="randomized-statistics-and-dotplot" class="section level2">
<h2>1-8 Randomized statistics and dotplot</h2>
<p>By permuting the home ownership variable multiple times, you generate differences in proportions that are consistent with the assumption that the variables are unrelated. The statistic of interest is the difference in proportions given by stat = “diff in props”. After calculating the randomized statistics, you will plot them in a dotplot.</p>
<p>This exercise shows all four steps from the infer package:</p>
<p>specify will specify the response and explanatory variables.
hypothesize will declare the null hypothesis.
generate will generate resamples, permutations, or simulations.
calculate will calculate summary statistics.
Each step will be covered throughout the course; in this exercise you’ll write code for calculate().</p>
<p>The dplyr, ggplot2, NHANES, and infer packages have been loaded for you. Repeat the permuting and plotting with 100 differences in proportions generated by shuffling the HomeOwn variable.</p>
<pre class="r"><code># Perform 100 permutations
homeown_perm &lt;- homes %&gt;%
  specify(HomeOwn ~ Gender, success = &quot;Own&quot;) %&gt;%
  hypothesize(null = &quot;independence&quot;) %&gt;% 
  generate(reps = 100, type = &quot;permute&quot;) %&gt;% 
  calculate(&quot;diff in props&quot;, order = c(&quot;male&quot;, &quot;female&quot;))
  
# Print results to console
homeown_perm</code></pre>
<pre><code>## # A tibble: 100 x 2
##    replicate      stat
##        &lt;int&gt;     &lt;dbl&gt;
##  1         1 -0.00577 
##  2         2 -0.00247 
##  3         3 -0.000827
##  4         4 -0.00948 
##  5         5 -0.0165  
##  6         6  0.00494 
##  7         7  0.0189  
##  8         8  0.00659 
##  9         9 -0.0115  
## 10        10 -0.00453 
## # ... with 90 more rows</code></pre>
<pre class="r"><code># Perform 100 permutations
homeown_perm &lt;- homes %&gt;%
  specify(HomeOwn ~ Gender, success = &quot;Own&quot;) %&gt;%
  hypothesize(null = &quot;independence&quot;) %&gt;% 
  generate(reps = 100, type = &quot;permute&quot;) %&gt;% 
  calculate(stat = &quot;diff in props&quot;, order = c(&quot;male&quot;, &quot;female&quot;))
  
# Dotplot of 100 permuted differences in proportions
ggplot(homeown_perm, aes(x = stat)) + 
  geom_dotplot(binwidth=0.001)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-8-1.png" width="672" /></p>
</div>
<div id="randomization-density" class="section level2">
<h2>1-9 Randomization density</h2>
<p>Using 100 repetitions allows you to understand the mechanism of permuting. However, 100 is not enough to observe the full range of likely values for the null differences in proportions.</p>
<p>Recall the four steps of inference. These are the same four steps that will be used in all inference exercises in this course and future statistical inference courses. Use the names of the functions to help you recall the analysis process.</p>
<p>specify will specify the response and explanatory variables.
hypothesize will declare the null hypothesis.
generate will generate resamples, permutations, or simulations.
calculate will calculate summary statistics.
In this exercise, you’ll repeat the process 1000 times to get a sense for the complete distribution of null differences in proportions.</p>
<pre class="r"><code># Perform 1000 permutations
homeown_perm &lt;- homes %&gt;%
  # Specify HomeOwn vs. Gender, with `&quot;Own&quot; as success
  specify(HomeOwn ~ Gender, success = &quot;Own&quot;) %&gt;%
  # Use a null hypothesis of independence
  hypothesize(null = &quot;independence&quot;) %&gt;% 
  # Generate 1000 repetitions (by permutation)
  generate(reps = 1000, type = &quot;permute&quot;) %&gt;% 
  # Calculate the difference in proportions (male then female)
  calculate(stat = &quot;diff in props&quot;, order = c(&quot;male&quot;, &quot;female&quot;))

# Density plot of 1000 permuted differences in proportions
ggplot(homeown_perm, aes(x = stat)) + 
  geom_density()</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-9-1.png" width="672" /></p>
</div>
<div id="do-the-data-come-from-the-population" class="section level2">
<h2>1-11 Do the data come from the population?</h2>
<p>Recall that the observed difference (i.e. the difference in proportions in the homes dataset, shown as the red vertical line) was around -0.0078, which seems to fall below the bulk of the density of shuffled differences. It is important to know, however, whether any of the randomly permuted differences were as extreme as the observed difference.</p>
<p>In this exercise, you’ll re-create this dotplot as a density plot and count the number of permuted differences that were to the left of the observed difference.</p>
<pre class="r"><code>head(homeown_perm1)</code></pre>
<pre><code>##   replicate    diff_perm    diff_orig
## 1         1 -0.002886141 -0.007828723
## 2         2 -0.002886141 -0.007828723
## 3         3  0.006587140 -0.007828723
## 4         4  0.004115849 -0.007828723
## 5         5  0.004939613 -0.007828723
## 6         6  0.004527731 -0.007828723</code></pre>
<pre class="r"><code># Plot permuted differences, diff_perm
ggplot(homeown_perm1, aes(x = diff_perm )) + 
  # Add a density layer
  geom_density() +
  # Add a vline layer with intercept diff_orig
  geom_vline(aes(xintercept = diff_orig), color = &quot;red&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<pre class="r"><code># Compare permuted differences to observed difference
homeown_perm1 %&gt;%
  summarize(n_perm_le_obs = sum(diff_perm  &lt;= diff_orig))</code></pre>
<pre><code>##   n_perm_le_obs
## 1           212</code></pre>
<ol start="17" style="list-style-type: upper-alpha">
<li><p>What can you conclude from the analysis?</p></li>
<li><p>We have learned that our data is consistent with the hypothesis of no difference in home ownership across gender.</p></li>
</ol>
</div>
<div id="completing-a-randomization-test-gender-discrimination" class="section level2">
<h2>2- Completing a randomization test: gender discrimination</h2>
<p>In this chapter, you will gain the tools and knowledge to complete a full hypothesis test. That is, given a dataset, you will know whether or not is appropriate to reject the null hypothesis in favor of the research claim of interest.</p>
</div>
<div id="summarizing-gender-discrimination" class="section level2">
<h2>2-3 Summarizing gender discrimination</h2>
<p>As the first step of any analysis, you should look at and summarize the data. Categorical variables are often summarized using proportions, and it is always important to understand the denominator of the proportion.</p>
<p>Do you want the proportion of women who were promoted or the proportion of promoted individuals who were women? Here, you want the first of these, so in your R code it’s necessary to group_by() the sex variable.</p>
<pre class="r"><code>disc</code></pre>
<pre><code>##         promote    sex
## 1      promoted   male
## 2      promoted   male
## 3      promoted   male
## 4      promoted   male
## 5      promoted   male
## 6      promoted   male
## 7      promoted   male
## 8      promoted   male
## 9      promoted   male
## 10     promoted   male
## 11     promoted   male
## 12     promoted   male
## 13     promoted   male
## 14     promoted   male
## 15     promoted   male
## 16     promoted   male
## 17     promoted   male
## 18     promoted   male
## 19     promoted female
## 20     promoted female
## 21     promoted female
## 22     promoted female
## 23     promoted female
## 24     promoted female
## 25     promoted female
## 26     promoted female
## 27     promoted female
## 28     promoted female
## 29     promoted female
## 30     promoted female
## 31     promoted female
## 32     promoted female
## 33     promoted female
## 34     promoted female
## 35     promoted female
## 36 not_promoted   male
## 37 not_promoted   male
## 38 not_promoted   male
## 39 not_promoted   male
## 40 not_promoted   male
## 41 not_promoted   male
## 42 not_promoted female
## 43 not_promoted female
## 44 not_promoted female
## 45 not_promoted female
## 46 not_promoted female
## 47 not_promoted female
## 48 not_promoted female</code></pre>
<pre class="r"><code># Create a contingency table summarizing the data
disc %&gt;%
  # Count the rows by sex, promote
  count(sex, promote)</code></pre>
<pre><code>##      sex      promote  n
## 1 female not_promoted  7
## 2 female     promoted 17
## 3   male not_promoted  6
## 4   male     promoted 18</code></pre>
<pre class="r"><code># Find proportion of each sex who were promoted
disc %&gt;%
  # Group by sex
  group_by(sex) %&gt;%
  # Calculate proportion promoted summary stat
  summarise(promoted_prop=mean(promote==&quot;promoted&quot;))</code></pre>
<pre><code>## # A tibble: 2 x 2
##   sex    promoted_prop
##   &lt;fct&gt;          &lt;dbl&gt;
## 1 female         0.708
## 2 male           0.75</code></pre>
</div>
<div id="step-by-step-through-the-permutation" class="section level2">
<h2>2-4 Step-by-step through the permutation</h2>
<p>To help you understand the code used to create the randomization distribution, this exercise will walk you through the steps of the infer framework. In particular, you’ll see how differences in the generated replicates affect the calculated statistics.</p>
<p>After running the infer steps, be sure to notice that the numbers are slightly different for each replicate.</p>
<pre class="r"><code># Replicate the entire data frame, permuting the promote variable
disc_perm &lt;- disc %&gt;%
  specify(promote ~ sex, success = &quot;promoted&quot;) %&gt;%
  hypothesize(null = &quot;independence&quot;) %&gt;%
  generate(reps = 5, type = &quot;permute&quot;)

disc_perm %&gt;%
  # Group by replicate
  group_by(replicate) %&gt;%
  # Count per group
  count(promote)</code></pre>
<pre><code>## # A tibble: 10 x 3
## # Groups:   replicate [5]
##    replicate promote          n
##        &lt;int&gt; &lt;fct&gt;        &lt;int&gt;
##  1         1 not_promoted    13
##  2         1 promoted        35
##  3         2 not_promoted    13
##  4         2 promoted        35
##  5         3 not_promoted    13
##  6         3 promoted        35
##  7         4 not_promoted    13
##  8         4 promoted        35
##  9         5 not_promoted    13
## 10         5 promoted        35</code></pre>
<pre class="r"><code>disc_perm %&gt;%
  # Calculate difference in proportion, male then female
  calculate(stat= &quot;diff in props&quot;, order= c(&quot;male&quot;, &quot;female&quot;))</code></pre>
<pre><code>## # A tibble: 5 x 2
##   replicate    stat
##       &lt;int&gt;   &lt;dbl&gt;
## 1         1  0.208 
## 2         2  0.125 
## 3         3 -0.0417
## 4         4 -0.125 
## 5         5 -0.0417</code></pre>
</div>
<div id="randomizing-gender-discrimination" class="section level2">
<h2>2-5 Randomizing gender discrimination</h2>
<p>Recall that we are considering a situation where the number of men and women are fixed (representing the resumes) and the number of people promoted is fixed (the managers were able to promote only 35 individuals).</p>
<p>In this exercise, you’ll create a randomization distribution of the null statistic with 1000 replicates as opposed to just 5 in the previous exercise. As a reminder, the statistic of interest is the difference in proportions promoted between genders (i.e. proportion for males minus proportion for females). From the original dataset, you can calculate how the promotion rates differ between males and females. Using the specify-hypothesis-generate-calculate workflow in infer, you can calculate the same statistic, but instead of getting a single number, you get a whole distribution. In this exercise, you’ll compare that single number from the original dataset to the distribution made by the simulation.</p>
<pre class="r"><code># Calculate the observed difference in promotion rate
diff_orig &lt;- disc %&gt;%
  # Group by sex
  group_by(sex) %&gt;%
  # Summarize to calculate fraction promoted
  summarize(prop_prom = mean(promote == &quot;promoted&quot;)) %&gt;%
  # Summarize to calculate difference
  summarize(stat = diff(prop_prom)) %&gt;% 
  pull()
    
# See the result
diff_orig</code></pre>
<pre><code>## [1] 0.04166667</code></pre>
<pre class="r"><code># Create data frame of permuted differences in promotion rates
disc_perm &lt;- disc %&gt;%
  # Specify promote vs. sex
  specify(promote~sex, success = &quot;promoted&quot;) %&gt;%
  # Set null hypothesis as independence
  hypothesize(null = &quot;independence&quot;) %&gt;%
  # Generate 1000 permutations
  generate(reps = 1000, type = &quot;permute&quot;) %&gt;%
  # Calculate difference in proportions
  calculate(stat = &quot;diff in props&quot;, order = c(&quot;male&quot;, &quot;female&quot;))</code></pre>
<pre class="r"><code># From previous steps
diff_orig &lt;- disc %&gt;%
  group_by(sex) %&gt;%
  summarize(prop_prom = mean(promote == &quot;promoted&quot;)) %&gt;%
  summarize(stat = diff(prop_prom)) %&gt;% 
  pull()
disc_perm &lt;- disc %&gt;%
  specify(promote ~ sex, success = &quot;promoted&quot;) %&gt;%
  hypothesize(null = &quot;independence&quot;) %&gt;%
  generate(reps = 1000, type = &quot;permute&quot;) %&gt;%
  calculate(stat = &quot;diff in props&quot;, order = c(&quot;male&quot;, &quot;female&quot;))
  
# Using permutation data, plot stat
ggplot(disc_perm, aes(x = stat)) + 
  # Add a histogram layer
  geom_histogram(binwidth = 0.01) +
  # Add a vertical line at diff_orig
  geom_vline(aes(xintercept = diff_orig), color = &quot;red&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-15-1.png" width="672" /></p>
</div>
<div id="critical-region" class="section level2">
<h2>2-8 Critical region</h2>
<p>It seems as though the statistic—a difference in promotion rates of 0.2917—is on the extreme end of the permutation distribution. That is, there are very few permuted differences which are as extreme as the observed difference.</p>
<p>To quantify the extreme permuted (null) differences, we use the quantile() function.</p>
<pre class="r"><code>disc_perm %&gt;% 
  summarize(
    # Find the 0.9 quantile of diff_perm&#39;s stat
    q.90 = quantile(stat, p = 0.9),
    # ... and the 0.95 quantile
    q.95 = quantile(stat, p = 0.95),
    # ... and the 0.99 quantile
    q.99 = quantile(stat, p = 0.99)
  )</code></pre>
<pre><code>## # A tibble: 1 x 3
##    q.90  q.95  q.99
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 0.125 0.208 0.292</code></pre>
</div>
<div id="two-sided-critical-region" class="section level2">
<h2>2-9 Two-sided critical region</h2>
<p>For the discrimination data, the question at hand is whether or not women were promoted less often than men. However, there are often scenarios where the research question centers around a difference without directionality.</p>
<p>For example, you might be interested in whether the rate of promotion for men and women is different. In that case, a difference in proportions of -0.29 is just as “extreme” as a difference of positive 0.29.</p>
<p>If you had seen that women were promoted more often, what would the other side of the distribution of permuted differences look like? That is, what are the smallest (negative) values of the distribution of permuted differences?</p>
<pre class="r"><code># Use disc_perm
disc_perm %&gt;% 
  # ... to calculate summary stats
  summarize(
    # Find the 0.01 quantile of stat
    q.01 = quantile(stat, p = 0.01),
    # ... and 0.05
    q.05 = quantile(stat, p = 0.05),
    # ... and 0.1 
    q.10 = quantile(stat, p = 0.1)
  )</code></pre>
<pre><code>## # A tibble: 1 x 3
##     q.01   q.05   q.10
##    &lt;dbl&gt;  &lt;dbl&gt;  &lt;dbl&gt;
## 1 -0.292 -0.208 -0.125</code></pre>
<pre class="r"><code>disc_perm</code></pre>
<pre><code>## # A tibble: 1,000 x 2
##    replicate    stat
##        &lt;int&gt;   &lt;dbl&gt;
##  1         1  0.0417
##  2         2 -0.0417
##  3         3 -0.125 
##  4         4  0.125 
##  5         5  0.208 
##  6         6 -0.208 
##  7         7  0.125 
##  8         8  0.0417
##  9         9 -0.208 
## 10        10  0.208 
## # ... with 990 more rows</code></pre>
<pre class="r"><code># For an unknown reason, result is not same as DataCamp result. Therefore, I added below line:
#disc_perm &lt;- read.csv(&quot;disc_perm.csv&quot;)
#disc_perm</code></pre>
</div>
<div id="sample-size-in-randomization-distribution" class="section level2">
<h2>2-12 Sample size in randomization distribution</h2>
<p>We’ve created two new datasets for you with essentially the same difference in proportions as the original discrimination data. However, one of the datasets (disc_small) is one third the size of the original dataset and the other (disc_big) is 10 times larger than the original dataset.</p>
<p>Additionally, the same permutation code used previously has been run on the small and big datasets to create small and big distributions of permuted differences in promotion rates (disc_small_perm and disc_big_perm, respectively).</p>
<p>In this exercise, you’ll use these two new distributions to get a sense for how the differences vary given widely different sample sizes. In particular, notice the range of variability on the x-axis of each plot.</p>
<pre class="r"><code># Tabulate the small dataset
disc_small %&gt;% 
  # Select sex and promote
  count(sex, promote)</code></pre>
<pre><code>##      sex      promote n
## 1 female not_promoted 3
## 2 female     promoted 5
## 3   male not_promoted 1
## 4   male     promoted 7</code></pre>
<pre class="r"><code># Do the same for disc_big
disc_big %&gt;% 
  # Select sex and promote
  count(sex, promote)</code></pre>
<pre><code>##      sex      promote   n
## 1 female not_promoted 100
## 2 female     promoted 140
## 3   male not_promoted  30
## 4   male     promoted 210</code></pre>
<pre class="r"><code>diff_orig_small &lt;- 0.25

# Using disc_perm_small, plot stat
ggplot(disc_perm_small, aes(x = stat)) + 
  # Add a histogram layer with binwidth 0.01
  geom_histogram(binwidth = 0.01) +
  # Add a vline layer, crossing x-axis at diff_orig_small
  geom_vline(aes(xintercept = diff_orig_small), color = &quot;red&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-19-1.png" width="672" /></p>
<pre class="r"><code>diff_orig_big &lt;- 0.2916667

# Swap the dataset to disc_perm_big
ggplot(disc_perm_big, aes(x = stat)) + 
  geom_histogram(binwidth = 0.01) +
  # Change the x-axis intercept to diff_orig_big
  geom_vline(aes(xintercept = diff_orig_big), color = &quot;red&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-20-1.png" width="672" /></p>
</div>
<div id="sample-size-for-critical-region" class="section level2">
<h2>2-13 Sample size for critical region</h2>
<p>Using the randomization distributions with the small and big datasets, calculate different cutoffs for significance. Remember, you are most interested in a large positive difference in promotion rates, so you are calculating the upper quantiles of 0.90, 0.95, and 0.99.</p>
<pre class="r"><code>calc_upper_quantiles &lt;- function(dataset) {
  dataset %&gt;% 
    summarize(
      q.90 = quantile(stat, p = 0.90),
      q.95 = quantile(stat, p = 0.95),
      q.99 = quantile(stat, p = 0.99)
    )
}

# Recall the quantiles associated with the original dataset
calc_upper_quantiles(disc_perm)</code></pre>
<pre><code>## # A tibble: 1 x 3
##    q.90  q.95  q.99
##   &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1 0.125 0.208 0.292</code></pre>
<pre class="r"><code># Calculate the quantiles associated with the small dataset
calc_upper_quantiles(disc_perm_small)</code></pre>
<pre><code>##   q.90 q.95 q.99
## 1 0.25 0.25  0.5</code></pre>
<pre class="r"><code># Calculate the quantiles associated with the big dataset
calc_upper_quantiles(disc_perm_big)</code></pre>
<pre><code>##   q.90       q.95 q.99
## 1 0.05 0.06666667  0.1</code></pre>
</div>
<div id="calculating-the-p-values" class="section level2">
<h2>2- 15 Calculating the p-values</h2>
<p>In the video, you learned that a p-value measures the degree of disagreement between the data and the null hypothesis. Here, you will calculate the p-value for the original discrimination dataset as well as the small and big versions, disc_small and disc_big.</p>
<p>The original differences in proportions are available in your workspace, diff_orig, diff_orig_small, and diff_orig_big, as are the permuted datasets, disc_perm, disc_perm_small, and disc_perm_big.</p>
<p>Recall that you’re only interested in the one-sided hypothesis test here. That is, you’re trying to answer the question, “Are men more likely to be promoted than women?”</p>
<pre class="r"><code># Visualize and calculate the p-value for the original dataset
disc_perm %&gt;%
  visualize(obs_stat = diff_orig, direction = &quot;greater&quot;)</code></pre>
<pre><code>## Warning: `visualize()` should no longer be used to plot a p-value. Arguments
## `obs_stat`, `obs_stat_color`, `pvalue_fill`, and `direction` are deprecated. Use
## `shade_p_value()` instead.</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-22-1.png" width="672" /></p>
<pre class="r"><code>disc_perm %&gt;%
  get_p_value(obs_stat = diff_orig, direction = &quot;greater&quot;)</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.492</code></pre>
<pre class="r"><code># Visualize and calculate the p-value for the small dataset
#disc_perm_small %&gt;%
#  visualize(obs_stat = diff_orig_small, direction = &quot;greater&quot;)

disc_perm_small %&gt;%
  get_p_value(obs_stat = diff_orig_small, direction = &quot;greater&quot;)</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.282</code></pre>
<pre class="r"><code># Visualize and calculate the p-value for the big dataset
#disc_perm_big %&gt;%
#  visualize(obs_stat = diff_orig_big, direction = &quot;greater&quot;)

disc_perm_big %&gt;%
  get_p_value(obs_stat = diff_orig_big, direction = &quot;greater&quot;)</code></pre>
<pre><code>## Warning: Please be cautious in reporting a p-value of 0. This result is an
## approximation based on the number of `reps` chosen in the `generate()` step. See
## `?get_p_value()` for more information.</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1       0</code></pre>
</div>
<div id="practice-calculating-p-values" class="section level2">
<h2>2- 16 Practice calculating p-values</h2>
<p>In the original dataset, 87.5% of the men were promoted and 58.3% of the women were promoted.</p>
<p>Consider a situation where there are 24 men, 24 women, and 35 people are still promoted. But in this new scenario, 75% of the men are promoted and 70.8% of the women are promoted. Does the difference in promotion rates still appear to be statistically significant? That is, could this difference in promotion rates have come from random chance?</p>
<p>You’ll analyze these new data, contained in disc_new, using the same permutation algorithm from before.</p>
<pre class="r"><code># Recall the original data
disc %&gt;% 
  count(sex, promote)</code></pre>
<pre><code>##      sex      promote  n
## 1 female not_promoted  7
## 2 female     promoted 17
## 3   male not_promoted  6
## 4   male     promoted 18</code></pre>
<pre class="r"><code># Tabulate the new data
table(disc)</code></pre>
<pre><code>##               sex
## promote        female male
##   not_promoted      7    6
##   promoted         17   18</code></pre>
<pre class="r"><code>diff_orig_new &lt;- 0.04166667
# Recall the distribution of the original permuted differences
ggplot(disc_perm, aes(x = stat)) + 
  geom_histogram() +
  geom_vline(aes(xintercept = diff_orig), color = &quot;red&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-24-1.png" width="672" /></p>
<pre class="r"><code># Plot the distribution of the new permuted differences
ggplot(disc_perm_new, aes(x = stat))+ 
  geom_histogram() +
  geom_vline(aes(xintercept = diff_orig_new), color = &quot;red&quot;)</code></pre>
<pre><code>## `stat_bin()` using `bins = 30`. Pick better value with `binwidth`.</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-24-2.png" width="672" /></p>
<pre class="r"><code># Recall the p-value from the original data
disc_perm %&gt;%
  summarize(p_value = mean(diff_orig &lt;= stat))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.492</code></pre>
<pre class="r"><code># Find the p-value from the new data
disc_perm_new %&gt;%
  summarize(p_value = mean(diff_orig_new &lt;= stat))</code></pre>
<pre><code>##   p_value
## 1   0.227</code></pre>
</div>
<div id="calculating-two-sided-p-values" class="section level2">
<h2>2- 17 Calculating two-sided p-values</h2>
<p>What if the original research hypothesis had focused on any difference in promotion rates between men and women instead of focusing on whether men are more likely to be promoted than women? In this case, a difference like the one observed would occur twice as often (by chance) because sometimes the difference would be positive and sometimes it would be negative.</p>
<p>When there is no directionality to the alternative hypothesis, the hypothesis and p-value are considered to be two-sided. In a two-sided setting, the p-value is double the one-sided p-value.</p>
<p>In this exercise, you’ll calculate a two-sided p-value given the original randomization distribution and dataset.</p>
<p>The observed difference is stored in diff_orig and the difference in each permutation is the stat column of disc_perm.</p>
<pre class="r"><code># Calculate the two-sided p-value
disc_perm %&gt;%
  summarize(p_value = 2*mean(diff_orig &lt;= stat))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.984</code></pre>
</div>
<div id="hypothesis-testing-errors-opportunity-cost" class="section level2">
<h2>3- Hypothesis testing errors: opportunity cost</h2>
<p>You will continue learning about hypothesis testing with a new example and the same structure of randomization tests. In this chapter, however, the focus will be on different errors (type I and type II), how they are made, when one is worse than another, and how things like sample size and effect size impact the error rates.</p>
</div>
<div id="summarizing-opportunity-cost-1" class="section level2">
<h2>3-2 Summarizing opportunity cost (1)</h2>
<p>As you saw in the video, we’re interested in whether the treatment and control groups were equally likely to buy a DVD after reading the experimental statements.</p>
<p>In this exercise, you’ll use the data from the study to find the sample statistics (here: proportions) that are needed for the analysis.</p>
<pre class="r"><code>opportunity</code></pre>
<pre><code>##     decision     group
## 1     buyDVD   control
## 2     buyDVD   control
## 3     buyDVD   control
## 4     buyDVD   control
## 5     buyDVD   control
## 6     buyDVD   control
## 7     buyDVD   control
## 8     buyDVD   control
## 9     buyDVD   control
## 10    buyDVD   control
## 11    buyDVD   control
## 12    buyDVD   control
## 13    buyDVD   control
## 14    buyDVD   control
## 15    buyDVD   control
## 16    buyDVD   control
## 17    buyDVD   control
## 18    buyDVD   control
## 19    buyDVD   control
## 20    buyDVD   control
## 21    buyDVD   control
## 22    buyDVD   control
## 23    buyDVD   control
## 24    buyDVD   control
## 25    buyDVD   control
## 26    buyDVD   control
## 27    buyDVD   control
## 28    buyDVD   control
## 29    buyDVD   control
## 30    buyDVD   control
## 31    buyDVD   control
## 32    buyDVD   control
## 33    buyDVD   control
## 34    buyDVD   control
## 35    buyDVD   control
## 36    buyDVD   control
## 37    buyDVD   control
## 38    buyDVD   control
## 39    buyDVD   control
## 40    buyDVD   control
## 41    buyDVD   control
## 42    buyDVD   control
## 43    buyDVD   control
## 44    buyDVD   control
## 45    buyDVD   control
## 46    buyDVD   control
## 47    buyDVD   control
## 48    buyDVD   control
## 49    buyDVD   control
## 50    buyDVD   control
## 51    buyDVD   control
## 52    buyDVD   control
## 53    buyDVD   control
## 54    buyDVD   control
## 55    buyDVD   control
## 56    buyDVD   control
## 57    buyDVD treatment
## 58    buyDVD treatment
## 59    buyDVD treatment
## 60    buyDVD treatment
## 61    buyDVD treatment
## 62    buyDVD treatment
## 63    buyDVD treatment
## 64    buyDVD treatment
## 65    buyDVD treatment
## 66    buyDVD treatment
## 67    buyDVD treatment
## 68    buyDVD treatment
## 69    buyDVD treatment
## 70    buyDVD treatment
## 71    buyDVD treatment
## 72    buyDVD treatment
## 73    buyDVD treatment
## 74    buyDVD treatment
## 75    buyDVD treatment
## 76    buyDVD treatment
## 77    buyDVD treatment
## 78    buyDVD treatment
## 79    buyDVD treatment
## 80    buyDVD treatment
## 81    buyDVD treatment
## 82    buyDVD treatment
## 83    buyDVD treatment
## 84    buyDVD treatment
## 85    buyDVD treatment
## 86    buyDVD treatment
## 87    buyDVD treatment
## 88    buyDVD treatment
## 89    buyDVD treatment
## 90    buyDVD treatment
## 91    buyDVD treatment
## 92    buyDVD treatment
## 93    buyDVD treatment
## 94    buyDVD treatment
## 95    buyDVD treatment
## 96    buyDVD treatment
## 97    buyDVD treatment
## 98  nobuyDVD   control
## 99  nobuyDVD   control
## 100 nobuyDVD   control
## 101 nobuyDVD   control
## 102 nobuyDVD   control
## 103 nobuyDVD   control
## 104 nobuyDVD   control
## 105 nobuyDVD   control
## 106 nobuyDVD   control
## 107 nobuyDVD   control
## 108 nobuyDVD   control
## 109 nobuyDVD   control
## 110 nobuyDVD   control
## 111 nobuyDVD   control
## 112 nobuyDVD   control
## 113 nobuyDVD   control
## 114 nobuyDVD   control
## 115 nobuyDVD   control
## 116 nobuyDVD   control
## 117 nobuyDVD treatment
## 118 nobuyDVD treatment
## 119 nobuyDVD treatment
## 120 nobuyDVD treatment
## 121 nobuyDVD treatment
## 122 nobuyDVD treatment
## 123 nobuyDVD treatment
## 124 nobuyDVD treatment
## 125 nobuyDVD treatment
## 126 nobuyDVD treatment
## 127 nobuyDVD treatment
## 128 nobuyDVD treatment
## 129 nobuyDVD treatment
## 130 nobuyDVD treatment
## 131 nobuyDVD treatment
## 132 nobuyDVD treatment
## 133 nobuyDVD treatment
## 134 nobuyDVD treatment
## 135 nobuyDVD treatment
## 136 nobuyDVD treatment
## 137 nobuyDVD treatment
## 138 nobuyDVD treatment
## 139 nobuyDVD treatment
## 140 nobuyDVD treatment
## 141 nobuyDVD treatment
## 142 nobuyDVD treatment
## 143 nobuyDVD treatment
## 144 nobuyDVD treatment
## 145 nobuyDVD treatment
## 146 nobuyDVD treatment
## 147 nobuyDVD treatment
## 148 nobuyDVD treatment
## 149 nobuyDVD treatment
## 150 nobuyDVD treatment</code></pre>
<pre class="r"><code># Tabulate the data
opportunity %&gt;%
  count(decision, group)</code></pre>
<pre><code>##   decision     group  n
## 1   buyDVD   control 56
## 2   buyDVD treatment 41
## 3 nobuyDVD   control 19
## 4 nobuyDVD treatment 34</code></pre>
<pre class="r"><code># Find the proportion who bought the DVD in each group
opportunity %&gt;%
  group_by(group) %&gt;%
  summarize(buy_prop = mean(decision==&quot;buyDVD&quot;))</code></pre>
<pre><code>## # A tibble: 2 x 2
##   group     buy_prop
##   &lt;chr&gt;        &lt;dbl&gt;
## 1 control      0.747
## 2 treatment    0.547</code></pre>
</div>
<div id="plotting-opportunity-cost" class="section level2">
<h2>3-3 Plotting opportunity cost</h2>
<p>Again, interest is in whether the treatment and control groups were equally likely to buy a DVD after reading the experimental statements. Here, you’ll create a barplot to visualize the difference in proportions between the treatment and control groups.</p>
<pre class="r"><code># Plot group, filled by decision
ggplot(opportunity, aes(x = group, fill = decision)) + 
  # Add a bar layer, with position &quot;fill&quot;
  geom_bar(position=&quot;fill&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-28-1.png" width="672" /></p>
</div>
<div id="randomizing-opportunity-cost" class="section level2">
<h2>3-4 Randomizing opportunity cost</h2>
<p>As in Chapter 2 Exercise 5, you will permute the data to generate a distribution of differences as if the null hypothesis were true.</p>
<p>In the study, the number of individuals in each of the control and treatment groups is fixed. Additionally, when you assume that the null hypothesis is true—that is, the experiment had no effect on the outcome of buying a DVD—it is reasonable to infer that the number of individuals who would buy a DVD is also fixed. That is, 97 people were going to buy a DVD regardless of which treatment group they were in.</p>
<p>Using the new data and the methods from the previous chapter, create a randomization distribution of the difference in proportions calculated on permuted data.</p>
<pre class="r"><code># Calculate the observed difference in purchase rate
diff_obs &lt;- opportunity %&gt;%
  # Group by group
  group_by(group) %&gt;%
  # Calculate proportion deciding to buy a DVD
  summarise(prop_buy = mean(decision==&quot;buyDVD&quot;)) %&gt;%
  # Calculate difference between groups
  summarise(stat = diff(prop_buy)) %&gt;% 
  pull()</code></pre>
<pre class="r"><code># Create data frame of permuted differences in purchase rates
opp_perm &lt;- opportunity %&gt;%
  # Specify decision vs. group, where success is buying a DVD
  specify(decision~ group, success = &quot;buyDVD&quot;) %&gt;%
  # Set the null hypothesis to independence
  hypothesize(null = &quot;independence&quot;) %&gt;%
  # Generate 1000 reps of type permute
  generate(reps = 1000, type = &quot;permute&quot;) %&gt;%
  # Calculate the summary stat difference in proportions
  calculate(stat = &quot;diff in props&quot;, order = c(&quot;treatment&quot;, &quot;control&quot;))
    
# Review the result
opp_perm</code></pre>
<pre><code>## # A tibble: 1,000 x 2
##    replicate    stat
##        &lt;int&gt;   &lt;dbl&gt;
##  1         1  0.0133
##  2         2 -0.0133
##  3         3 -0.0133
##  4         4 -0.0133
##  5         5  0.0933
##  6         6  0.0933
##  7         7 -0.0400
##  8         8  0.147 
##  9         9 -0.0933
## 10        10  0.0133
## # ... with 990 more rows</code></pre>
<pre class="r"><code># From previous steps
diff_obs &lt;- opportunity %&gt;%
  group_by(group) %&gt;%
  summarize(prop_buy = mean(decision == &quot;buyDVD&quot;)) %&gt;%
  summarize(stat = diff(prop_buy)) %&gt;% 
  pull()
opp_perm &lt;- opportunity %&gt;%
  specify(decision ~ group, success = &quot;buyDVD&quot;) %&gt;%
  hypothesize(null = &quot;independence&quot;) %&gt;%
  generate(reps = 1000, type = &quot;permute&quot;) %&gt;%
  calculate(stat = &quot;diff in props&quot;, order = c(&quot;treatment&quot;, &quot;control&quot;))
  
# Using the permuation data, plot stat
ggplot(opp_perm, aes(x = stat)) + 
  # Add a histogram layer with binwidth 0.005
  geom_histogram(binwidth = 0.005) +
  # Add a vline layer with intercept diff_obs
  geom_vline(aes(xintercept = diff_obs), color = &quot;red&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-31-1.png" width="672" /></p>
</div>
<div id="summarizing-opportunity-cost-2" class="section level2">
<h2>3-5 Summarizing opportunity cost (2)</h2>
<p>Now that you’ve created the randomization distribution, you’ll use it to assess whether the observed difference in proportions is consistent with the null difference. You will measure this consistency (or lack thereof) with a p-value, or the proportion of permuted differences less than or equal to the observed difference.</p>
<p>The permuted dataset and the original observed statistic are available in your workspace as opp_perm and diff_orig respectively.</p>
<p>visualize and get_p_value using the built in infer functions. Remember that the null statistics are above the original difference, so the p-value (which represents how often a null value is more extreme) is calculated by counting the number of null values which are less than the original difference.</p>
<pre class="r"><code># Visualize the statistic 
opp_perm %&gt;%
  visualize(obs_stat = diff_orig, direction = &quot;less&quot;)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-32-1.png" width="672" /></p>
<pre class="r"><code># Calculate the p-value using `get_p_value`
opp_perm %&gt;%
  get_p_value(obs_stat = diff_orig, direction = &quot;less&quot;)</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.762</code></pre>
<pre class="r"><code># Calculate the p-value using `summarize`
opp_perm %&gt;%
  summarize(p_value = mean(stat &lt;= diff_orig))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1   0.762</code></pre>
<p>Q: In the last exercise, you computed the p-value, or the proportion of permuted differences less than or equal to the observed difference:</p>
<p>opp_perm %&gt;%
summarize(p_value = mean(stat &lt;= diff_orig))</p>
<p>Based on this result of 0.017, what can you conclude from the study about the effect of reminding students to save money?</p>
<p>A: Reminding them causes them to be less likely to buy the DVD.</p>
<div id="section" class="section level38">
<p class="heading"></p>
<p>Q: (Different choice of error rate) Consider again a situation where the task is to differentiate the proportion of successes across two different groups. What decision should be made if the goal is to never make a type II error (false negative)?</p>
<p>A: Always claim there is a difference in proportions.</p>
</div>
<div id="section-1" class="section level38">
<p class="heading"></p>
<p>Q:Errors for two-sided hypotheses
Sometimes you’ll be interested in identifying any difference in proportions (as opposed to one larger proportion). Consider these slightly adjusted hypotheses for the opportunity cost example:</p>
<p>H0: Reminding students that they can save money for later purchases will not have any impact on students’ spending decisions.</p>
<p>HA: Reminding students that they can save money for later purchases will change the chance they will continue with a purchase.
What are type I (false positive) and type II (false negative) errors for the two-sided hypotheses related to the opportunity costs example?</p>
<p>A: Type I: There is not a difference in proportions, but the observed difference is big enough to indicate that the proportions are different.</p>
<p>Type II: There is a difference in proportions, but the observed difference is not large enough to indicate that the proportions are different.</p>
</div>
</div>
<div id="p-value-for-two-sided-hypotheses-opportunity-costs" class="section level2">
<h2>3-10 p-value for two-sided hypotheses: opportunity costs</h2>
<p>The p-value measures the likelihood of data as or more extreme than the observed data, given the null hypothesis is true. Therefore, the appropriate p-value for a two-sided alternative hypothesis is a two-sided p-value.</p>
<p>To find a two-sided p-value, you simply double the one sided p-value. That is, you want to find two times the proportion of permuted differences that are less than or equal to the observed difference.</p>
<p>The opp_perm data frame, containing the differences in permuted proportions, and the original observed statistic, diff_orig, are available in your workspace.</p>
<pre class="r"><code>opp_perm</code></pre>
<pre><code>## # A tibble: 1,000 x 2
##    replicate    stat
##        &lt;int&gt;   &lt;dbl&gt;
##  1         1 -0.0933
##  2         2  0.0133
##  3         3  0.0933
##  4         4  0.0667
##  5         5  0.12  
##  6         6 -0.0667
##  7         7 -0.0133
##  8         8  0.0133
##  9         9 -0.0133
## 10        10  0.0933
## # ... with 990 more rows</code></pre>
<pre class="r"><code># Calculate the two-sided p-value
opp_perm %&gt;%
  summarize(p_value = 2* mean(stat &lt;= diff_orig))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   p_value
##     &lt;dbl&gt;
## 1    1.52</code></pre>
</div>
<div id="confidence-intervals" class="section level2">
<h2>4- Confidence intervals</h2>
<p>As a complement to hypothesis testing, confidence intervals allow you to estimate a population parameter. Recall that your interest is always in some characteristic of the population, but you only have incomplete information to estimate the parameter using sample data. Here, the parameter is the true proportion of successes in a population. Bootstrapping is used to estimate the variability needed to form the confidence interval.</p>
<p>Q: What is the parameter?</p>
<p>In November 2016, the voters elected a new president of the United States. Prior to the election, thousands of polls were taken to gauge the popularity of each of the candidates. Leaving aside the idea that popular opinion changes over time, a poll can be thought of as a sample of individuals measured so as to estimate the proportion of all voters who will vote for each candiate (i.e. the population parameter).</p>
<p>Consider an election in your home town that will take place in a week’s time. You poll a randomly selected subset of the voters in your town and ask them if they plan to vote for Candidate X or Candidate Y. In this chapter, we will focus on sampling variability—the variability in sample proportions due to polling different randomly selected individuals from the population.</p>
<p>Before investigating the sampling variability, what is the population parameter of interest?</p>
<p>A: The proportion of all voters in your town who will vote for Candidate X on election day.</p>
<p>Q:Hypothesis test or confidence interval?</p>
<p>A university is trying to determine whether parking is a problem on its campus. The student newspaper contacts a random sample of 200 students and asks whether or not they are frustrated with the parking situation. They want to estimate the proportion of students at the college who are frustrated with the parking situation.</p>
<p>In this setting, which is more appropriate, a hypothesis test or a confidence interval?</p>
<p>A:Confidence interval because the goal is to estimate a population parameter.</p>
</div>
<div id="resampling-from-a-sample" class="section level2">
<h2>4-5 Resampling from a sample</h2>
<p>To investigate how much the estimates of a population proportion change from sample to sample, you will set up two sampling experiments.</p>
<p>In the first experiment, you will simulate repeated samples from a population. In the second, you will choose a single sample from the first experiment and repeatedly resample from that sample: a method called bootstrapping. More specifically:</p>
<p>Experiment 1: Assume the true proportion of people who will vote for Candidate X is 0.6. Repeatedly sample 30 people from the population and measure the variability of
(the sample proportion).</p>
<p>Experiment 2: Take one sample of size 30 from the same population. Repeatedly sample 30 people (with replacement!) from the original sample and measure the variability of
(the resample proportion).</p>
<p>It’s important to realize that the first experiment relies on knowing the population and is typically impossible in practice. The second relies only on the sample of data and is therefore easy to implement for any statistic. Fortunately, as you will see, the variability in
, or the proportion of “successes” in a sample, is approximately the same whether we sample from the population or resample from a sample.</p>
<p>We have created 1000 random samples, each of size 30, from the population. The resulting data frame, all_polls, is available in your workspace. Take a look before getting started.</p>
<pre class="r"><code># Compute p-hat for each poll
ex1_props &lt;- all_polls %&gt;% 
  # Group by poll
  group_by(poll) %&gt;% 
  # Calculate proportion of yes votes
  summarise(stat = mean(vote == &quot;yes&quot;))
  
# Review the result
ex1_props</code></pre>
<pre><code>## # A tibble: 1,000 x 2
##     poll  stat
##    &lt;int&gt; &lt;dbl&gt;
##  1     1 0.7  
##  2     2 0.667
##  3     3 0.633
##  4     4 0.633
##  5     5 0.4  
##  6     6 0.6  
##  7     7 0.5  
##  8     8 0.533
##  9     9 0.567
## 10    10 0.567
## # ... with 990 more rows</code></pre>
<pre class="r"><code># Select one poll from which to resample
one_poll &lt;- all_polls %&gt;%
  # Filter for the first poll
  filter(poll==&quot;1&quot;) %&gt;%
  # Select vote
  select(vote)
  
# Compute p-hat* for each resampled poll
ex2_props &lt;- one_poll %&gt;%
  # Specify vote as the response, where yes means success
  specify(response = vote, success = &quot;yes&quot;) %&gt;%
  # Generate 1000 reps of type bootstrap
  generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% 
  # Calculate the summary stat &quot;prop&quot;
  calculate(stat = &quot;prop&quot;)</code></pre>
<pre class="r"><code># From previous steps
ex1_props &lt;- all_polls %&gt;% 
  group_by(poll) %&gt;% 
  summarize(stat = mean(vote == &quot;yes&quot;))
ex2_props &lt;- all_polls %&gt;%
  filter(poll == 1) %&gt;%
  select(vote) %&gt;%
  specify(response = vote, success = &quot;yes&quot;) %&gt;%
  generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% 
  calculate(stat = &quot;prop&quot;)
  
# Calculate variability of p-hat
ex1_props %&gt;% 
  summarize(variability = sd(stat))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   variability
##         &lt;dbl&gt;
## 1      0.0868</code></pre>
<pre class="r"><code># Calculate variability of p-hat*
ex2_props %&gt;% 
  summarize(variability = sd(stat))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   variability
##         &lt;dbl&gt;
## 1      0.0844</code></pre>
</div>
<div id="visualizing-the-variability-of-p-hat" class="section level2">
<h2>4-6 Visualizing the variability of p-hat</h2>
<p>In order to compare the variability of the sampled
and
values in the previous exercises, it is valuable to visualize their distributions. To recall, the exercises walked through two different experiments for investigating the variability of P and P*:</p>
<p>Experiment 1: Sample () repeatedly from an extremely large population (gold standard, but unrealistic)</p>
<p>Experiment 2: Resample () repeatedly with replacement from a single sample of size 30</p>
<pre class="r"><code># Combine data from both experiments
both_ex_props &lt;- bind_rows(ex1_props, ex2_props, .id = &quot;experiment&quot;)

# Using both_ex_props, plot stat colored by experiment
ggplot(both_ex_props, aes(stat, color = experiment)) + 
  # Add a density layer with bandwidth 0.1
  geom_density(bw = 0.1)</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-37-1.png" width="672" /></p>
<p>Q: Always resample the original number of observations</p>
<p>In the bootstrap examples, exactly 30 observations have been repeatedly resampled from the original sample. The choice of 30 was given because the original sample had 30 observations. If we had resampled 3 observations instead, the resampled
value could have ranged from 0 to 1 (producing a much larger
than desired). If we had resampled 300 observations instead, the resampled
value would have been close to the same number each time (producing a much smaller
than desired).</p>
<p>Generally, if represents the size of the original sample, how many observations should we resample with replacement when bootstrapping?</p>
<p>A: Resample exactly n observations because then the variability of P^* will be most similar / representative of the original sampling process.</p>
</div>
<div id="empirical-rule" class="section level2">
<h2>4-9 Empirical Rule</h2>
<p>Many statistics we use in data analysis (including both the sample average and sample proportion) have nice properties that are used to better understand the population parameter(s) of interest.</p>
<p>One such property is that if the variability of the sample proportion (called the standard error, or ) is known, then approximately 95% of
values (from different samples) will be within of the true population proportion.</p>
<p>To check whether that holds in the situation at hand, let’s go back to the polls generated by taking many samples from the same population.</p>
<p>The all_polls dataset contains 1000 samples of size 30 from a population with a probability of voting for Candidate X equal to 0.6.</p>
<p>Note that you will use the R function sd() which calculates the variability of any set of numbers. In statistics, when sd() is applied to a variable (e.g., price of house) we call it the standard deviation. When sd() is applied to a statistic (e.g., set of sample proportions) we call it the standard error.</p>
<pre class="r"><code># Proportion of yes votes by poll
props &lt;- all_polls %&gt;% 
  group_by(poll) %&gt;% 
  summarize(prop_yes = mean(vote == &quot;yes&quot;))

# The true population proportion of yes votes
true_prop_yes &lt;- 0.6

# Proportion of polls within 2SE
props %&gt;%
  # Add column: is prop_yes in 2SE of 0.6
  mutate(is_in_conf_int = abs(prop_yes - true_prop_yes) &lt; 2 * sd(prop_yes)) %&gt;%
  # Calculate  proportion in conf int
  summarize(prop_in_conf_int = mean(is_in_conf_int))</code></pre>
<pre><code>## # A tibble: 1 x 1
##   prop_in_conf_int
##              &lt;dbl&gt;
## 1            0.966</code></pre>
</div>
<div id="bootstrap-t-confidence-interval" class="section level2">
<h2>4-10 Bootstrap t-confidence interval</h2>
<p>The previous exercises told you two things:</p>
<p>You can measure the variability associated with
by resampling from the original sample.
Once you know the variability of
, you can use it as a way to measure how far away the true proportion is.
Note that the rate of closeness (here 95%) refers to how often a sample is chosen so that it is close to the population parameter. You won’t ever know if a particular dataset is close to the parameter or far from it, but you do know that over your lifetime, 95% of the samples you collect should give you estimates that are within of the true population parameter.</p>
<p>The votes from a single poll, one_poll, and the data from 1000 bootstrap resamples, one_poll_boot are available in your workspace. These are based on Experiment 2 from earlier in the chapter.</p>
<p>As in the previous exercise, when discussing the variability of a statistic, the number is referred to as the standard error.</p>
<pre class="r"><code># From previous exercises
one_poll &lt;- all_polls %&gt;%
  filter(poll == 1) %&gt;%
  select(vote)
one_poll_boot &lt;- one_poll %&gt;%
  specify(response = vote, success = &quot;yes&quot;) %&gt;%
  generate(reps = 1000, type = &quot;bootstrap&quot;) %&gt;% 
  calculate(stat = &quot;prop&quot;)
  
p_hat &lt;- one_poll %&gt;%
  # Calculate proportion of yes votes
  summarize(stat = mean(vote == &quot;yes&quot;)) %&gt;%
  pull()

# Create an interval of plausible values
one_poll_boot %&gt;%
  summarize(
    # Lower bound is p_hat minus 2 std errs
    lower = p_hat- 2 * sd(stat),
    # Upper bound is p_hat plus 2 std errs
    upper = p_hat+ 2 * sd(stat)
  )</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower upper
##   &lt;dbl&gt; &lt;dbl&gt;
## 1 0.531 0.869</code></pre>
</div>
<div id="bootstrap-percentile-interval" class="section level2">
<h2>4-11 Bootstrap percentile interval</h2>
<p>The main idea in the previous exercise was that the distance between the original sample
and the resampled (or bootstrapped)
values gives a measure for how far the original
is from the true population proportion.</p>
<p>The same variability can be measured through a different mechanism. As before, if
is sufficiently close to the true parameter, then the resampled (bootstrapped)
values will vary in such a way that they overlap with the true parameter.</p>
<p>Instead of using as a way to measure the middle 95% of the sampled
values, you can find the middle of the resampled
values by removing the upper and lower 2.5%. Note that this second method of constructing bootstrap intervals also gives an intuitive way for making 90% or 99% confidence intervals as well as 95% intervals.</p>
<p>The bootstrapped resamples, one_poll_boot, and the proportion of yes votes, p_hat are available in your workspace.</p>
<pre class="r"><code># From previous exercise: bootstrap t-confidence interval
one_poll_boot %&gt;%
  summarize(
    lower = p_hat - 2 * sd(stat),
    upper = p_hat + 2 * sd(stat)
  )</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower upper
##   &lt;dbl&gt; &lt;dbl&gt;
## 1 0.531 0.869</code></pre>
<pre class="r"><code># Manually calculate a 95% percentile interval
one_poll_boot %&gt;%
  summarize(
    lower = quantile(stat, p = 0.025),
    upper = quantile(stat, p = 0.975)
  )</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower upper
##   &lt;dbl&gt; &lt;dbl&gt;
## 1 0.533 0.867</code></pre>
<pre class="r"><code># From previous step
one_poll_boot %&gt;%
  summarize(
    lower = quantile(stat, 0.025),
    upper = quantile(stat, 0.975)
  )</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower upper
##   &lt;dbl&gt; &lt;dbl&gt;
## 1 0.533 0.867</code></pre>
<pre class="r"><code># Calculate the same interval, more conveniently
percentile_ci &lt;- one_poll_boot %&gt;% 
  get_confidence_interval(level = 0.95)
  
# Review the value
percentile_ci</code></pre>
<pre><code>## # A tibble: 1 x 2
##   lower_ci upper_ci
##      &lt;dbl&gt;    &lt;dbl&gt;
## 1    0.533    0.867</code></pre>
<pre class="r"><code># From previous step
percentile_ci &lt;- one_poll_boot %&gt;% 
  get_confidence_interval(level = 0.95)
  
one_poll_boot %&gt;% 
  # Visualize in-between the endpoints given by percentile_ci
  visualize(endpoints=percentile_ci , direction = &quot;between&quot;)</code></pre>
<pre><code>## Warning: `visualize()` should no longer be used to plot a confidence interval.
## Arguments `endpoints`, `endpoints_color`, and `ci_fill` are deprecated. Use
## `shade_confidence_interval()` instead.</code></pre>
<p><img src="{{< blogdown/postref >}}index.en_files/figure-html/unnamed-chunk-42-1.png" width="672" /></p>
</div>
<div id="sample-size-effects-on-bootstrap-cis" class="section level2">
<h2>4-13 Sample size effects on bootstrap CIs</h2>
<p>In a previous multiple choice exercise, you realized that if you resampled the data with the wrong size (e.g. 300 or 3 instead of 30), the standard error (SE) of the sample proportions was off. With 300 resampled observations, the SE was too small. With 3 resampled observations, the SE was too large.</p>
<p>Here, you will use the incorrect standard error (based on the incorrect sample size) to create a confidence interval. The idea is that when the standard error is off, the interval is not particularly useful, nor is it correct.</p>
</div>
<div id="sample-proportion-value-effects-on-bootstrap-cis" class="section level2">
<h2>4-14 Sample proportion value effects on bootstrap CIs</h2>
<p>One additional element that changes the width of the confidence interval is the sample parameter value,
.</p>
<p>Generally, when the true parameter is close to 0.5, the standard error of
is larger than when the true parameter is closer to 0 or 1. When calculating a bootstrap t-confidence interval, the standard error controls the width of the CI, and here (given a true parameter of 0.8) the sample proportion is higher than in previous exercises, so the width of the confidence interval will be narrower.</p>
</div>
<div id="percentile-effects-on-bootstrap-cis" class="section level2">
<h2>4-15 Percentile effects on bootstrap CIs</h2>
<p>Most scientists use 95% intervals to quantify their uncertainty about an estimate. That is, they understand that over a lifetime of creating confidence intervals, only 95% of them will actually contain the parameter that they set out to estimate.</p>
<p>There are studies, however, which warrant either stricter or more lenient confidence intervals (and subsequent error rates).</p>
<p>The previous bootstrapped
values have been loaded for you and are available in one_poll_boot.</p>
</div>
