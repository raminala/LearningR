---
title: Reshaping Data with tidyr
author: ''
date: '2021-10-04'
slug: reshaping-data-with-tidyr
categories: []
tags:
  - data_wrangling
  - dataset_preparation
---

```{r include=FALSE}
library(tidyverse)

netflix_df <- read_csv("netflix_df.csv")
phone_nr_df <- read_csv("phone_nr_df.csv")
tvshow_df <- read_csv("tvshow_df.csv")
drink_df <-  read_csv("drink_df.csv")
director_df <-  read_csv("director_df.csv")
sales_df <-  read_csv("sales_df.csv")
country_to_continent_df <-  read_csv("country_to_continent_df.csv")
nuke_df <-  read_csv("nuke_df.csv")
obesity_df <-  read_csv("obesity_df.csv")
nuke_df2 <-  read_csv("nuke_df2.csv")
bond_df <-  read_csv("bond_df.csv")
bird_df <-  read_csv("bird_df.csv")
stock_df <-  read_csv("stock_df.csv")
space_dogs_df <-  read_csv("space_dogs_df.csv")
who_df <-  read_csv("who_df.csv")
dog_df <-  read_csv("dog_df.csv")
space_dogs_df2  <-  read_csv("space_dogs_df2.csv")
planet_df  <-  read_csv("planet_df.csv")
planet_df2 <-  read_csv("planet_df2.csv")
space_df <-  read_csv("space_df.csv")
dates1 <-  read_csv("dates.csv")
dates <- dates1$x
reactor_df <-  read_csv("reactor_df.csv")
olympic <- readRDS("olympic_medals_top_10.rds")
```


Data in the wild can be scary—when confronted with a complicated and messy dataset you may find yourself wondering, where do I even start? The tidyr package allows you to wrangle such beasts into nice and tidy datasets. Inaccessible values stored in column names will be put into rows, JSON files will become data frames, and missing values will never go missing again. You'll practice these techniques on a wide range of messy datasets, learning along the way how many dogs the Soviet Union sent into space and what bird is most popular in New Zealand. With the tidyr package in your tidyverse toolkit, you'll be able to transform almost any dataset in a tidy format which will pay-off during the rest of your analysis.

## 1- Tidy data

You'll be introduced to the concept of tidy data which is central to this course. In the first two lessons, you'll jump straight into the action by separating messy character columns into tidy variables and observations ready for analysis. In the final lesson, you'll learn how to overwrite and remove missing values.

## 1-3 Multiple variables per column

Being a busy person, you don't want to spend too much time on Netflix, so you decide to crunch some numbers on TV show and movie durations before deciding what to watch. You've managed to obtain a dataset named netflix_df, but its duration column has an issue. It contains strings with both a value and unit of duration ("min" or "Season").

You'll tidy this dataset so that each variable gets its own column.

```{r}
netflix_df %>% 
  # Split the duration column into value and unit columns
  separate(duration, into = c("value", "unit"), sep = " ", convert = TRUE)
```

## 1-5 International phone numbers

You work for a multinational company that uses auto-dialer software to contact its customers. When new customers subscribe online they are asked for a phone number but they often forget to add the country code needed for international calls. You were asked to fix this issue in the database. You've been given a data frame with national numbers and country codes named phone_nr_df. Now you want to combine the country_code and national_number columns to create valid international numbers.

```{r}
phone_nr_df

phone_nr_df %>%
  # Unite the country_code and national_number columns
  unite("international_number", country_code, national_number, sep = " ")
```

## 1-6 Extracting observations from values

You're given a sample of the Netflix dataset containing TV shows and their casts called tvshow_df. You want to learn which six actors have the most appearances.

However, the dataset only has one row per TV show, and multiple actors are listed in the cast column.

Transform the data so that for each TV show, every actor has a row. The number of appearances will be calculated for you.

```{r}
tvshow_df

tvshow_df %>% 
  # Separate the actors in the cast column over multiple rows
  separate_rows(cast, sep = ", ", convert = TRUE) %>% 
  rename(actor = cast) %>% 
  count(actor, sort = TRUE) %>% 
  head()
```

## 1-7 Separating into columns and rows

Remember the drink ingredients data from the video? You've been given an similar version (drink_df) that also includes quantities and units. Now you want to create an overview of how much of each ingredient you should buy to make these drinks.


```{r}
drink_df


drink_df %>% 
  # Separate the ingredients over rows
  separate_rows(ingredients, sep = "; ") %>% 
  # Separate ingredients into three columns
  separate(
    ingredients, 
    into = c("ingredient", "quantity", "unit"), 
    sep = " ", 
    convert = TRUE
  ) %>% 
  # Group by ingredient and unit
  group_by(ingredient, unit) %>% 
  # Calculate the total quantity of each ingredient
  summarize(quantity = sum(quantity))
```

## 1-9 And the Oscar for best director goes to ... <NA>

You're working on a sample of the Netflix dataset pre-loaded as director_df. This time, the data frame contains just the directors and movie titles. Your goal is to identify the directors who created the most movies. Since the director column contains multiple names, you'll first separate its values over multiple rows and then count the directors.

Since you don't want movies without directors polluting your overview, you'll apply the drop_na() function.

```{r}
director_df %>% 
  # Spread the director column over separate rows
  separate_rows(director, sep = ", ") %>% 
  # Count the number of movies per director
  count(director, sort=TRUE)
```

```{r}
director_df %>% 
  # Drop rows with NA values in the director column
  drop_na() %>% 
  # Spread the director column over separate rows
  separate_rows(director, sep = ", ") %>% 
  # Count the number of movies per director
  count(director, sort = TRUE)
```

## 1-10 Imputing sales data

You've been asked to create a report that allows management to compare sales figures per quarter for two years. The problem is that the dataset (sales_df) contains missing values. You'll need to impute the values in the year column so that you can visualize the data.

```{r}
sales_df %>% 
  # Impute the year column
  fill(year, .direction = "up") %>%
  # Create a line plot with sales per quarter colored by year.
  ggplot(aes(x = quarter, y = sales, color = as.factor(year), group = year)) +
  geom_line()
```

## 1-11 Nuclear bombs per continent

Since WWII, a number of nations have been detonating nuclear bombs for military research. A tally of bombs detonated per nation has been calculated from the Nuclear Explosion DataBase (NEDB) and provided as nuke_df. You are interested in finding out how many bombs have been detonated by nations grouped per continent. To achieve this goal, nuke_df will be joined to country_to_continent_df which is a mapping of nation to continent. You will need to overwrite missing values with zeros so that you can create a nice plot.

The dplyr and ggplot2 packages have been pre-loaded for you.

Side note 1: Bombs detonated by the Soviet Union were attributed to the Russian Federation.

Side note 2: The Russian Federation is solely mapped to Europe for simplicity.

```{r}
country_to_continent_df %>% 
  left_join(nuke_df, by = "country_code") %>%  
  # Impute the missing values in the n_bombs column with 0L
  replace_na(list(n_bombs = 0L)) %>% 
  # Group the dataset by continent
  group_by(continent) %>% 
  # Sum the number of bombs per continent
  summarize(n_bombs_continent = sum(n_bombs)) %>% 
  # Plot the number of bombs per continent
  ggplot(aes(continent, n_bombs_continent)) +
  geom_col()
```

## 2- From wide to long and back

This chapter is all about pivoting data from a wide to long format and back again using the `pivot_longer()` and `pivot_wider()` functions. You'll need these functions when variables are hidden in messy column names or when variables are stored in rows instead of columns. You'll learn about space dogs, nuclear bombs, and planet temperatures along the way.

## 2-2 Nuclear bombs per country

You've been given a version of the Nuclear Explosion DataBase (NEDB) where country names are specified in the column headers (nuke_df). You want to visualize how many nukes were detonated per year per country. You'll need to pivot the data and replace NA values first.

```{r}
nuke_df2

nuke_df2 %>% 
  # Pivot the data to a longer format
  pivot_longer(-year)
```

```{r}
nuke_df2 %>% 
  # Pivot the data to a longer format
  pivot_longer(
    -year, 
    # Overwrite the names of the two new columns
    names_to = "country", 
     values_to = "n_bombs"
  ) 
```

```{r}
nuke_df2 %>% 
  # Pivot the data to a longer format
  pivot_longer(
    -year, 
    # Overwrite the names of the two new columns
    names_to = "country", 
    values_to = "n_bombs"
  ) %>%
  # Replace NA values for n_bombs with 0L
   replace_na(list(n_bombs = 0L))
```

```{r}
nuke_df2 %>% 
  # Pivot the data to a longer format
  pivot_longer(
    -year, 
    # Overwrite the names of the two new columns
    names_to = "country", 
    values_to = "n_bombs"
  ) %>% 
  # Replace NA values for n_bombs with 0L
  replace_na(list(n_bombs = 0L)) %>% 
  # Plot the number of bombs per country over time
  ggplot(aes(year,n_bombs, color=country)) +
  geom_line()
```


## 2-3 WHO obesity per country

According to the World Health Organization (WHO), worldwide obesity has nearly tripled since 1975. You're interested in the severity of this global health issue per country and whether males and females are affected differently. You'll use the WHO's obesity data (obesity_df) to investigate this issue. The data holds the percentage of females, males, and both sexes combined that are considered obese (BMI > 30) per country.

You want to create a scatterplot where, per nation, you can see the obesity data colored differently for females and males. This implies that sex should become a variable with its own column.

```{r}
obesity_df

obesity_df %>% 
  # Pivot the male and female columns
  pivot_longer(c(male,female), names_to = "sex", 
    values_to = "pct_obese")
```

```{r}
obesity_df %>% 
  # Pivot the male and female columns
  pivot_longer(c(male, female),
               names_to = "sex",
               values_to = "pct_obese") %>% 
  # Create a scatter plot with pct_obese per country colored by sex
  ggplot(aes(x = pct_obese, color = sex,
             y = forcats::fct_reorder(country, both_sexes))) +
  geom_point() +
  scale_y_discrete(breaks = c("India", "Nauru", "Cuba", "Brazil",
                              "Pakistan", "Gabon", "Italy", "Oman",
                              "China", "United States of America")) +
  labs(x = "% Obese", y = "Country")
```


## 2-4 Bond... James Bond

You've been given a James Bond movie dataset (bond_df) and want to visualize the number of movies that Bond actors have featured in per decade. However, the data is in an untidy format with the decade values captured in the column headers. You'll tidy this dataset to give each variable its own column.

```{r warning=FALSE}
bond_df %>% 
  # Pivot the data to long format
  pivot_longer(
    -Bond, 
    # Overwrite the names of the two newly created columns
    names_to = "decade", 
    values_to = "n_movies", 
    # Drop na values
    values_drop_na = TRUE, 
    # Transform the decade column data type to integer
   names_transform= list(decade = as.integer)
  ) %>% 
  ggplot(aes(x = decade + 5, y = n_movies, fill = Bond))+
  geom_col()
```

## 2-6 New-Zealand's bird of the year

Every year New Zealanders vote en masse to decide which species gets the bird of the year trophy. The contest is organized by the Forest & Bird agency which allows each person to give points to up to five birds (first pick gets 5 points, second 4, …). Your job is to decide this year's winner from the messy dataset that's been pre-loaded for you as bird_df.

```{r}
bird_df

bird_df %>%
  # Pivot the data to create a two column data frame
  pivot_longer(
    c(points_1, points_2, points_3, points_4, points_5),
    names_to = "points",
    names_prefix = "points_",
    names_transform = list(points = as.integer),
    values_to = "species",
    values_drop_na = TRUE
  )
```

Alternative solution...

```{r}
bird_df %>%
  # Pivot the data to create a two column data frame
  pivot_longer(
     starts_with("points_"),
    names_to = "points",
    names_prefix = "points_",
    names_transform = list(points = as.integer),
    values_to = "species",
    values_drop_na = TRUE
  ) %>%
  group_by(species) %>% 
  summarize(total_points=sum(points)) %>% 
  slice_max(total_points, n = 5)
```


## 2-7 Big tech stock prices

You're an analyst at an investment firm and want to visualize the weekly closing prices of five big tech firms' stocks. However, the dataset you've been handed (stock_df) is messy and has the year and week variables stored in the column headers. You'll pivot this data into a tidy format, extract the variables from the headers, and create a line plot.

```{r}
stock_df

ss <- stock_df %>% 
  # Pivot the data to create 3 new columns: year, week, price
  pivot_longer(
    -company,
    names_to = c("year", "week"),
    values_to = "price",
    names_sep = "_week",
    names_transform = list(year = as.integer, week = as.integer)
  ) 

ss

ss %>%
  # Create a line plot with price per week, color by company
  ggplot(aes(week, price, color=company)) +
  geom_line() +
  facet_grid(. ~ year)
```

## 2-9 Soviet space dogs, the dog perspective

You'll be working on an pre-processed sample of the USSR space dogs database compiled by Duncan Geere and pre-loaded for you as space_dogs_df. Each of the 42 rows in this dataset represents a test rocket launch which had one or two very brave dogs on board.

Your goal is to reshape this dataset so that for each launch, each dog has a row.

The challenge is that in the column headers (name_1, name_2, gender_1, and gender_2), the part before the _ separator can point to two different variables (name and gender), while the second part always points to the dog ID (1st or 2nd dog).

Complete the names_to argument so that the first part of the column headers are reused.

```{r}
space_dogs_df

space_dogs_df %>% 
  pivot_longer(
    # Add the columns to pivot
    name_1:gender_2,
    names_sep = "_",
    # Complete the names_to argument to re-use the first part of the column headers
    names_to = c(".value", "dog_id"),
    # Make sure NA values are dropped
    values_drop_na = TRUE
  )
```

## 2-10 WHO obesity vs. life expectancy

You've been given a sample of WHO data (who_df) with obesity percentages and life expectancy data per country, year, and sex. You want to visually inspect the correlation between obesity and life expectancy.

However, the data is very messy with four variables hidden in the column names. Each column name is made up of three parts separated by underscores: Values for the year, followed by those for sex, and then values for either pct.obese or life.exp. Since the third part of the column name string holds two variables you'll need to use the special ".value" value in the names_to argument.

You'll pivot the data into a tidy format and create the scatterplot.

```{r}
who_df

who_df %>% 
  # Put each variable in its own column
  pivot_longer(
    -country,
    names_to = c("year", "sex", ".value"),
    names_sep = "_", 
    names_transform = list("year" = as.integer)
  )
```


```{r}
who_df %>% 
  # Put each variable in its own column
  pivot_longer(
    -country,
    names_to = c("year", "sex", ".value"),
    names_sep = "_", 
    names_transform = list("year" = as.integer)
  ) %>%
  # Create a plot with life expectancy over obesity
  ggplot(aes(x=pct.obese, life.exp, color=sex))+geom_point()
```

## 2-11 Uncounting observations

You've found the job of your dreams providing technical support for a dog breed beauty contest. The jury members want a spreadsheet with the breed and id of each participating dog so that they can add the scores later on. You've only been given the number of participants per dog breed (dog_df) so you decide to use your tidyr skills to create the desired result.

```{r}
dog_df

dog_df %>% 
  # Create one row for each participant and add the id
  uncount(n_participants, .id = "dog_id")
```

## 2-13 Soviet space dogs, the flight perspective

Remember the USSR space dogs dataset1? You changed it to a long format so that for every dog in every rocket launch, there was a row. Suppose you're given this tidy dataset and are asked to answer the question, "In what percentage of flights were both dogs of the same gender?"

You'll reshape and investigate space_dogs_df to find the answer.

```{r}
space_dogs_df2

space_dogs_df2 %>% 
  # Pivot the data to a wider format
  pivot_wider(names_from = dog_id, values_from = gender, names_prefix = "gender_")
```

```{r}
space_dogs_df2 %>% 
  # Pivot the data to a wider format
  pivot_wider(names_from = dog_id, values_from = gender, names_prefix = "gender_") %>% 
  # Drop rows with NA values
  drop_na() %>% 
  # Create a Boolean column on whether both dogs have the same gender
  mutate(same_gender= ifelse(gender_1 == gender_2, 1, 0)) %>% 
  summarize(pct_same_gender = mean(same_gender))
```


## 2-14 Planet temperature & distance to the Sun

The intensity of light radiated by a light source follows an inverse square relationship with the distance it has traveled.

https://en.wikipedia.org/wiki/Inverse-square_law 

You wonder if you could observe this trend in the temperature of the planets in our Solar System given their distance to the Sun. You'll use the planet_df dataset from the devstronomy project to investigate this.

```{r}
planet_df
```
```{r}
r <- planet_df %>% 
  # Give each planet variable its own column
  pivot_wider(names_from = metric, values_from = value)

r
```

```{r}
r %>% 
  # Plot planet temperature over distance to sun
  ggplot(aes(distance_to_sun, temperature)) +
  geom_point(aes(size = diameter)) +
  geom_text(aes(label = planet), vjust = -1) +
  labs(x = "Distance to sun (million km)", 
       y = "Mean temperature (°C)") +
  theme(legend.position = "none")
```


## 2-15 Transposing planet data

You're again working on a planet dataset derived from the devstronomy project. This time, you're interested in the correlation between the diameter of a planet and the number of moons circling it.

However, the dataset (planet_df) has a row for each variable and a column for each planet (observation). You'll transpose this data in two steps and then create a plot to inspect the correlation.

```{r}
planet_df2 %>%
  # Pivot all columns except metric to long format
  pivot_longer(-metric, names_to = "planet") %>% 
  # Put each metric in its own column
  pivot_wider(names_from = metric, values_from = value) %>% 
  # Plot the number of moons vs planet diameter
  ggplot(aes(diameter, number_of_moons)) +
  geom_point(aes(size = diameter)) +
  geom_text(aes(label = planet), vjust = -1) +
  labs(x = "Diameter (km)", y = "Number of moons") +
  theme(legend.position = "none")
```

## 3- Expanding data

Values can often be missing in your data, and sometimes entire observations are absent too. In this chapter, you'll learn how to complete your dataset with these missing observations. You'll add observations with zero values to counted data, expand time series to a full sequence of intervals, and more!

## 3-2 Letters of the genetic code

The basic building blocks of RNA are four molecules described by a single letter each: adenine (A), cytosine (C), guanine (G), and uracil (U). The information carried by an RNA strand can be represented as a long sequence of these four letters. To read this code, one has to divide this chain into sequences of three letters each (e.g. GCU, ACG, …). These three letter sequences are known as codons. The concept is illustrated in the image below.

RNA code

Your goal for this exercise is to create a data frame with all possible three letter sequences (codons) from a vector with the four letters representing the RNA building blocks.

```{r}
letters <- c("A", "C", "G", "U")

# Create a tibble with all possible 3 way combinations
codon_df <- expand_grid(
  letter1 = letters,
  letter2 = letters,
  letter3 = letters
)

codon_df %>% 
  # Unite these three columns into a "codon" column
  unite("codon", letter1, letter2, letter3, sep = " ")
```

## 3-3 When did humans replace dogs in space?

You already know that in the early days of spaceflight, the USSR was testing rockets with dogs. You now wonder when exactly humans started replacing dogs on space flight missions. You've been given a dataset space_df with the number of both dogs (compiled by Duncan Geere) and humans in space per year from 1951 till 1970 (collected from Wikipedia).

Your goal is to create a plot that shows you the number of individuals sent into space per species. Before you can create this plot, you'll first have to introduce zero values for missing combinations of year and species.

```{r}
# Create a tibble with all combinations of years and species
full_df <- expand_grid(
    year = 1951:1970,   species = c("Human", "Dog"))

full_df

space_df %>% 
  # Join with full_df so that missing values are introduced
  right_join(full_df) %>% 
  arrange(year)
```

```{r message=FALSE}
space_df %>% 
  # Join with full_df so that missing values are introduced
  right_join(full_df) %>% 
  arrange(year)
```

```{r}
# Create a tibble with all combinations of years and species
full_df <- expand_grid(
  year = 1951:1970, 
  species = c("Human", "Dog")
)

space_df %>% 
  # Join with full_df so that missing values are introduced
  right_join(full_df, by = c("year", "species")) %>% 
  # Create a line plot with n_in_space over year, color by species
  ggplot(aes(year, n_in_space, color= species)) +
  geom_line()
```


```{r}
# Create a tibble with all combinations of years and species
full_df <- expand_grid(
  year = 1951:1970, 
  species = c("Human", "Dog")
)

space_df %>% 
  # Join with full_df so that missing values are introduced
  right_join(full_df, by = c("year", "species")) %>% 
  # Overwrite NA values for n_in_space with 0L
  replace_na(list(n_in_space = 0L)) %>% 
  # Create a line plot with n_in_space over year, color by species
  ggplot(aes(x = year, y = n_in_space, color = species)) +
  geom_line()
```

## 3-4 Finding missing observations

You're an inspector at a nuclear plant and have to validate whether every reactor has received its daily safety check over the course of a full year. The safety check logs are in reactor_df, a data frame with columns date, reactor, and check.

Two vectors, dates and reactors, with all dates of the year and reactors at the plant respectively have been created for you. You'll use the combination of the expand_grid() and anti_join() functions to find dates where particular reactors were not checked.




```{r}
reactors <- c("A", "B", "C", "D")

# Create a tibble with all combinations of dates and reactors
full_df <- expand_grid(date = dates, reactor = reactors)
full_df
# Find the reactor - date combinations not present in reactor_df
full_df %>% 
  anti_join(reactor_df, by = c("date", "reactor"))
```


## 3-6 Completing the Solar System

You have been given a data frame (planet_df) from the devstronomy project with the number of moons per planet in our Solar System. However, Mercury and Venus, the two moonless planets, are absent. You want to expand this dataset using the complete() function and a vector planets that contains all eight planet's names.

```{r}

```

## 3-7 Zero Olympic medals

Since 1896, athletes from all over the world have been competing in the modern Olympic games. You've been given a dataset (medal_df) with observations for all medals won by athletes from the 10 most successful countries in Olympic history. You want to create a visual with the number of medals won per country (team) per year. However, since not all countries won medals each year, you'll have to introduce zero values before you can make an accurate visual.

```{r}

```

## 3-8 Creating a sequence with full_seq()

The full_seq() function will look for the minimal and maximal values inside the vector you pass it and will then generate a full sequence of numbers with a fixed period in between them. When used inside the complete() function, full_seq() is a handy tool to make sure there are no missing observations in your data. Before combining these two functions you'll generate a few sequences with full_seq() on its own to get the hang of this function.

```{r}

```

## 3-9 The Cold War's hottest year

In October 1962, during the Cuban missile crisis, the world came close to a full scale nuclear war. Throughout 1962, the USA, USSR, and France together detonated a record 178 nuclear bombs for military power display and research. You've been given a sample of the Nuclear Explosion Database (NEDB) for that year (cumul_nukes_1962_df) with an observation for each date on which a bomb was detonated. The total_bombs variable contains the cumulative number of bombs detonated by a country up to that point in time.

You'll complete the dataset to hold the full sequence of dates, and visualize the total number of bombs per country over time. You'll also use the fill() function from Chapter One to impute missing values.

```{r}

```

## 3-11 Olympic medals per continent

You want to compare Olympic performance of athletes per continent over time, both on the winter and summer Olympics. You've been given a dataset medal_df with the average number of medals won per participant of each continent since 1928. You'll complete this data to introduce zero values for years where a continent did not win any medals.

```{r}

```

## 3-12 Tracking a virus outbreak

You're a doctor in a remote village confronted with a virus outbreak. You have been collecting data on when your patients got infected and recovered in a data frame named patient_df. Your goal is to create a visual with the number of sick patients over time. You'll first have to reshape the data so that you can count the number of sick patients per day.

```{r}

```

## 3-13 Counting office occupants

Imagine you're an office facility manager and want to know how many people are present throughout the day. You've installed a sensor at the entrance that counts the number of people entering and leaving the building. The sensor sends an update at the end of every 20 minute time slot if at least one person passed.

To create a dataset ready for visualization, you'll combine the different techniques you've learned so far.

```{r}

```

## 4- Rectangling data

In the final chapter, you'll learn how to turn nested data structures such as JSON and XML files into tidy, rectangular data. This skill will enable you to process data from web APIs. You'll also learn how nested data structures can be used to write elegant modeling pipelines that produce tidy outputs.


## 4-3 Rectangling Star Wars movies

Let's pretend you're a big Star Wars fan and decided to scrape some data from the Star Wars API. You've already loaded the JSON-formatted response into R, and now have two lists of movies named movie_list and movie_planets_list. Your goal is to turn these into rectangular data frames with one row per movie so that you can start crunching those movie stats.



```{r}

```


## 4-6 Rectangling Star Wars planets

Let's finish what we started in the last exercise of the previous lesson, exploring Star Wars planets! The movie_planets_list scraped from the Star Wars API has been pre-loaded for you. You'll need two specific unnesting operations to completely rectangle this data.

```{r}

```

## 4-7 The Solar System's biggest moons

Most planets in our solar system are accompanied by at least one moon. You now wonder which planets are circled by the biggest moons and want to create a top five based on moon radius. However, you'll first have to unnest the devstronomy project data in planet_df using the unnest_longer() and unnest_wider() functions.

```{r}

```

## 4-9 Hoisting Star Wars films

You've been given a nested data set on Star Wars characters (character_df) and want to explore the films in which they appeared. You'll first use the unnest_wider() and unnest_longer() functions to explore the data and will then switch to hoist() to select a specific element in the nested data structure directly.

```{r}

```

## 4-10 Hoisting movie ratings

You've written a script to scrape data on your favorite movies from the Open Movie DataBase API. Now you want to process the JSON data to extract the Rotten Tomatoes rating for each movie. You've been given a data frame named movie_df which holds the JSON respones for five movies. You'll explore this data with unnest_wider() and unnest_longer() before switching to hoist().


```{r}

```


## 4-13 Nesting tibbles

You're pre-processing the US army body measurement dataset ANSUR II to train multiple models in a single pipeline. You'll experiment with the nest() function to create a list column with nested tibbles containing sub-sets of the data.

```{r}

```

## 4-14 Modeling on nested data frames

You'll be working on the US Army ANSUR II body measurement dataset, which has been pre-loaded as ansur_df. The goal is to nest the data for both sexes so that you can simultaneously train two linear models, one for each sex. These models will derive a person's weight from their stature (height) and waist circumference. You'll then unnest the data to inspect the model's statistics produced by the glance() function from the broom package.

The dplyr, broom, and purrr packages have been pre-loaded for you.

Side note: In the provided code, the purrr package's map() function applies functions on each nested data frame. Check out this package if you like using functions inside pipes!

```{r}

```

